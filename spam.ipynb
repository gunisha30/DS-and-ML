{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spam.ipynb",
      "provenance": [],
      "mount_file_id": "1g7XEPYqKdVCQ9a48qNqcjg6A77Qv2dZt",
      "authorship_tag": "ABX9TyNv3FQgXlgvOlDM/jHqH1Ge",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gunisha30/projects/blob/master/spam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSyZaXEZiUih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "df = pd.read_csv(\"//content//drive//My Drive//spam.csv\")\n",
        "#frequency of ham and spam \n",
        "pd.crosstab(df['Label'],columns='freq')\n",
        "#stemming\n",
        "ps = nltk.PorterStemmer()\n",
        "#list of stopwords\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "#returns percentage of punctuations in text\n",
        "def punct_pc(text):\n",
        "    punct_count = sum([1 for char in text if char in string.punctuation])\n",
        "    return (punct_count/(len(text) - text.count(' ')))*100\n",
        "\n",
        "df['text_length'] = df['EmailText'].apply(lambda x : len(x)-x.count(' '))\n",
        "df['punct'] = df['EmailText'].apply(lambda x : punct_pc(x))\n",
        "\n",
        "#remove punctuations\n",
        "def clean_data(text):\n",
        "    punct = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
        "    splt = re.split('\\W+',punct)\n",
        "    txt = [ps.stem(word) for word in splt if word not in stopwords]\n",
        "    return txt\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(df[['EmailText','text_length','punct']],df['Label'],test_size=0.2,random_state=123)\n",
        "\n",
        "#vectorising using count vectorizer\n",
        "Count_vect_fit = Count_Vect.fit(X_train['EmailText'])\n",
        "\n",
        "X_train_Count_vect = Count_vect_fit.transform(X_train['EmailText'])\n",
        "X_test_Count_vect = Count_vect_fit.transform(X_test['EmailText'])\n",
        "\n",
        "X_train_Count_vect = pd.concat([X_train[['text_length','punct']].reset_index(drop=True) ,\n",
        "                         pd.DataFrame(X_train_Count_vect.toarray())],axis=1)\n",
        "\n",
        "\n",
        "X_test_Count_vect = pd.concat([X_test[['text_length','punct']].reset_index(drop=True) , \n",
        "                        pd.DataFrame(X_test_Count_vect.toarray())],axis=1)\n",
        "\n",
        "rf = RandomForestClassifier(random_state=123,n_jobs=3)\n",
        "param = {'n_estimators' : [10,25,50,100,300], 'max_depth' : [10, 20, 50,100, None],'max_features' : [10,50,'auto']}\n",
        "grid = GridSearchCV(rf,param,cv=5,n_jobs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3N_-9b1kYMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6BTydIJ1_Zs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "11439ee6-e0b5-4d4b-cea3-eb39de1fbb03"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew1Q0nYz2AON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOauEUfO6NsC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}